prototype-v1-Mobilenet
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_config_file=tfserv.conf.mobilenet
bazel-bin/tensorflow_serving/example/prototype_v1_master
bazel-bin/tensorflow_serving/example/prototype_v1_worker --worker localhost:50101
bazel-bin/tensorflow_serving/example/prototype_v1_worker --worker localhost:50102
bazel-bin/tensorflow_serving/example/prototype_v1_client

activity detection
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_config_file=tfserv.conf.activity.detection >out-001 2>&1
bazel-bin/tensorflow_serving/example/activity_detection_master
python main.py --video_src /home/yitao/Documents/fun-project/actions_demo/videos/indoor_two_ppl.avi

mobilenet
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_config_file=tfserv.conf.mobilenet >out-001 2>&1
bazel-bin/tensorflow_serving/example/mobilenet_client

SSD
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=exported_ssd --model_base_path=/home/yitao/Documents/fun-project/tensorflow-related/SSD-Tensorflow/exported_ssd
bazel-bin/tensorflow_serving/example/ssd_client

new
- darkflow
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=darkflow_yolo --model_base_path=/home/yitao/Documents/fun-project/darknet-repo/test/darkflow_yolo >out-001 2>&1
bazel-bin/tensorflow_serving/example/darkflow_yolo_client --server localhost:9000

- inception
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=inception --model_base_path=/tmp/inception_output >out-001 2>&1
bazel-bin/tensorflow_serving/example/inception_client_new --server localhost:9000 --image dog.jpg

- devicehive_yolo
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=devicehive_yolo --model_base_path=/home/yitao/Documents/fun-project/devicehive-video-analysis/devicehive_yolo_do_need_preprocess >out-001 2>&1
bazel-bin/tensorflow_serving/example/devicehive_yolo_client --server localhost:9000

- nvidia_autopilot
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=nvidia_autopilot --model_base_path=/home/yitao/Documents/fun-project/tensorflow-related/Autopilot-TensorFlow/nvidia_autopilot >out-001 2>&1
bazel-bin/tensorflow_serving/example/nvidia_autopilot_client
==================================================================================================================================
* Server:
  bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --enable_batching --batching_parameters_file=batching_config.txt --port=9000 --model_config_file=tfserv.conf.middleware >debug-out/out-001 2>&1
* Client:
  bazel-bin/tensorflow_serving/example/new_olympian_client --server localhost:9000

==================================================================================================================================

* Server:
  - Middleware
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --enable_batching --batching_parameters_file=batching_config.txt --port=9000 --model_config_file=tfserv.conf.middleware >debug-out/out001 2>&1

  - Inception and ResNet
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --enable_batching --batching_parameters_file=batching_config.txt --port=9000 --model_config_file=tfserv.conf >debug-out/out001 2>&1

  - GoogleNet
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=caffe_googlenet --model_base_path=/home/yitao/Documents/fun-project/caffe-tensorflow/examples/imagenet/caffe_googlenet >debug-out/out001 2>&1

  - MNIST
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=caffe_mnist --model_base_path=/home/yitao/Documents/fun-project/caffe-tensorflow/caffe_mnist >debug-out/out001 2>&1

  - VGG
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=vgg_model --model_base_path=/home/yitao/Documents/fun-project/tensorflow-vgg/vgg_model >debug-out/out001 2>&1

  - YOLO-1
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=yolo_tiny_batch_001 --model_base_path=/home/yitao/Documents/fun-project/tensorflow-yolo/yolo_tiny_batch_001 >debug-out/out001 2>&1
  - YOLO-32
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=yolo_tiny_batch_032 --model_base_path=/home/yitao/Documents/fun-project/tensorflow-yolo/yolo_tiny_batch_032 >debug-out/out001 2>&1
  - YOLO-128
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=yolo_tiny_batch_128 --model_base_path=/home/yitao/Documents/fun-project/tensorflow-yolo/yolo_tiny_batch_128 >debug-out/out001 2>&1

  - Darkflow
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=darkflow_yolo --model_base_path=/home/yitao/Documents/fun-project/darknet-repo/test/darkflow_yolo

  - Mobilenet
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_config_file=tfserv.conf.mobilenet >out-001 2>&1

* Client:
  - Inception and ResNet
    bazel-bin/tensorflow_serving/example/olympia_client --server localhost:9000

  - Inception
    bazel-bin/tensorflow_serving/example/inception_client --server localhost:9000

  - ResNet
    bazel-bin/tensorflow_serving/example/caffe_resnet_client --server localhost:9000

  - GoogleNet
    bazel-bin/tensorflow_serving/example/caffe_googlenet_client --server localhost:9000

  - MNIST
    bazel-bin/tensorflow_serving/example/caffe_mnist_client --server localhost:9000

  - VGG
    bazel-bin/tensorflow_serving/example/vgg_client --server localhost:9000

  - YOLO
    bazel-bin/tensorflow_serving/example/yolo_tiny_client --server localhost:9000

  - AlexNet
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=caffe_alexnet --model_base_path=/home/yitao/Documents/fun-project/caffe-tensorflow/examples/imagenet/caffe_alexnet >debug-out/out001 2>&1

  - caffe-VGG
    bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=caffe_vgg --model_base_path=/home/yitao/Documents/fun-project/caffe-tensorflow/examples/imagenet/caffe_vgg >debug-out/out001 2>&1

  - Darkflow
    bazel-bin/tensorflow_serving/example/darkflow_yolo_client --server localhost:9000

  - Mobilenet
    bazel-bin/tensorflow_serving/example/mobilenet_client

==================================================================================================================================

bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --enable_batching --batching_parameters_file=batching_config.txt --port=9000 --model_name=inception --model_base_path=/home/yitao/Downloads/tmp/inception_model
bazel-bin/tensorflow_serving/example/inception_client --server localhost:9000


*******************
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --enable_batching --batching_parameters_file=batching_config.txt --port=9000 --model_config_file=tfserv.conf
bazel-bin/tensorflow_serving/example/olympia_client --server localhost:9000


bazel-bin/tensorflow_serving/example/inception_client --server localhost:9000
bazel-bin/tensorflow_serving/example/caffe_googlenet_client --server localhost:9000

bazel-bin/tensorflow_serving/example/mnist_client --num_tests=10 --server=localhost:9000
*******************



# play with MNIST
rm -rf /home/yitao/Downloads/tmp/mnist_model
bazel-bin/tensorflow_serving/example/mnist_saved_model --training_iteration=100 --model_version=1 /home/yitao/Downloads/tmp/mnist_model
bazel-bin/tensorflow_serving/example/mnist_saved_model --training_iteration=2000 --model_version=2 /home/yitao/Downloads/tmp/mnist_model

rm -rf /home/yitao/Downloads/tmp/monitored
mkdir /home/yitao/Downloads/tmp/monitored
cp -r /home/yitao/Downloads/tmp/mnist_model/1 /home/yitao/Downloads/tmp/monitored
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=mnist --model_base_path=/home/yitao/Downloads/tmp/monitored

bazel-bin/tensorflow_serving/example/mnist_client --num_tests=10 --server=localhost:9000

cp -r /home/yitao/Downloads/tmp/mnist_model/2 /home/yitao/Downloads/tmp/monitored

bazel-bin/tensorflow_serving/example/mnist_client --num_tests=10 --server=localhost:9000




bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=inception --model_base_path=/home/yitao/Downloads/tmp/inception_model
bazel-bin/tensorflow_serving/example/inception_client --server localhost:9000




# play with Inception
curl -O http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz
tar xzf inception-v3-2016-03-01.tar.gz
bazel-bin/tensorflow_serving/example/inception_saved_model --checkpoint_dir=inception-v3 --output_dir=/home/yitao/Downloads/tmp/inception_model


bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=inception --model_base_path=/home/yitao/Downloads/tmp/inception_model
bazel-bin/tensorflow_serving/example/inception_client --server localhost:9000 --image dog.jpg





# Multiple models. Ex. MNIST and Inception
# cat tfserv.conf
model_config_list: {
  config: {
    name: "mnist",
    base_path: "/tmp/mnist_model",
    model_platform: "tensorflow"
  },
  config: {
    name: "inception",
    base_path: "/tmp/inception_model",
    model_platform: "tensorflow"
  }
}

bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_config_file=tfserv.conf

bazel-bin/tensorflow_serving/example/mnist_client --num_tests=10 --server=localhost:9000
bazel-bin/tensorflow_serving/example/inception_client --server localhost:9000 --image dog.jpg




# For Weimin's example
# https://weiminwang.blog/2017/09/12/introductory-guide-to-tensorflow-serving/
# https://github.com/sugartom/Serving-TensorFlow-Model
cd Documents/fun-project/Serving-TensorFlow-Model
python export_model.py
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=weimin_model --model_base_path=/home/yitao/Documents/fun-project/tensorflow-related/Serving-TensorFlow-Model
bazel-bin/tensorflow_serving/example/weimin_client --server localhost:9000


# For Gan example
# https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198
# https://github.com/sugartom/tf_serving_example
cd Documents/fun-project/tf_serving_example
python svnh_semi_supervised_model_train.py
python svnh_semi_supervised_model_saved.py --checkpoint-dir=./checkpoints --output_dir=./gan-export --model-version=1
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=gan_model --model_base_path=/home/yitao/Documents/fun-project/tf_serving_example/gan-export
bazel-bin/tensorflow_serving/example/gan_client --server localhost:9000 --image=/home/yitao/Documents/fun-project/tf_serving_example/svnh_test_images/image_3.jpg

# For Caffe-MNIST example
# https://github.com/sugartom/caffe-tensorflow/tree/master/examples/mnist
cd Documents/fun-project/caffe-tensorflow
./convert.py examples/mnist/lenet.prototxt --code-output-path=mynet.py
./convert.py examples/mnist/lenet.prototxt --caffemodel examples/mnist/lenet_iter_10000.caffemodel --data-output-path=mynet.npy
python finetune_mnist.py
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=caffe_mnist --model_base_path=/home/yitao/Documents/fun-project/caffe-tensorflow/caffe_mnist
bazel-bin/tensorflow_serving/example/caffe_mnist_client --server localhost:9000

# For Caffe-GoogleNet example
# https://github.com/sugartom/caffe-tensorflow/tree/master/examples/imagenet
cd Documents/fun-project/caffe-tensorflow/examples/imagenet
mkdir tomModels
cd tomModels
wget https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_googlenet/deploy.prototxt
wget http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel
cd ../../..
./convert.py examples/imagenet/tomModels/deploy.prototxt --code-output-path=examples/imagenet/tomModels/googlenet.py
./convert.py examples/imagenet/tomModels/deploy.prototxt --caffemodel examples/imagenet/tomModels/bvlc_googlenet.caffemodel --data-output-path=examples/imagenet/tomModels/googlenet.npy
cd examples/imagenet
mkdir caffe_googlenet
./classify.py tomModels/googlenet.npy /home/yitao/Documents/TF-Serving-Downloads/dog.jpg
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=caffe_googlenet --model_base_path=/home/yitao/Documents/fun-project/caffe-tensorflow/examples/imagenet/caffe_googlenet
bazel-bin/tensorflow_serving/example/caffe_googlenet_client --server localhost:9000 --image dog.jpg

# For Caffe-ResNet example
# Firstly, download prototxt and caffemodel files from Kaiming's website, then...
./convert.py examples/imagenet/tomModels/ResNet-50-deploy.prototxt --caffemodel examples/imagenet/tomModels/ResNet-50-model.caffemodel --data-output-path=examples/imagenet/tomModels/ResNet-50.npy
./convert.py examples/imagenet/tomModels/ResNet-101-deploy.prototxt --caffemodel examples/imagenet/tomModels/ResNet-101-model.caffemodel --data-output-path=examples/imagenet/tomModels/ResNet-101.npy
./convert.py examples/imagenet/tomModels/ResNet-152-deploy.prototxt --caffemodel examples/imagenet/tomModels/ResNet-152-model.caffemodel --data-output-path=examples/imagenet/tomModels/ResNet-152.npy
# !!! need to change model name in classify-resnet.py
./classify-resnet.py tomModels/ResNet-50.npy /home/yitao/Documents/TF-Serving-Downloads/dog.jpg
./classify-resnet.py tomModels/ResNet-152.npy /home/yitao/Documents/TF-Serving-Downloads/dog.jpg
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=caffe_resnet50 --model_base_path=/home/yitao/Documents/fun-project/caffe-tensorflow/examples/imagenet/caffe_resnet50
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=caffe_resnet152 --model_base_path=/home/yitao/Documents/fun-project/caffe-tensorflow/examples/imagenet/caffe_resnet152
bazel-bin/tensorflow_serving/example/caffe_resnet_client --server localhost:9000

# For VGG example
git clone https://github.com/sugartom/tensorflow-vgg.git
cd tensorflow-vgg
python tom_test_vgg16.py
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=vgg_model --model_base_path=/home/yitao/Documents/fun-project/tensorflow-vgg/vgg_model
bazel-bin/tensorflow_serving/example/vgg_client --server localhost:9000

# For DeviceHive YOLO
cd /home/yitao/Documents/fun-project/devicehive-yolo/yolo_ckpt
or
cd /home/yitao/Downloads/test/20180709/flow_yolo_ckpt
flow --model /home/yitao/Documents/fun-project/darknet-repo/darkflow/cfg/yolo.cfg --load /home/yitao/Documents/fun-project/darknet-repo/darkflow/bin/yolo.weights --gpu 0.8 --threshold 0.25 --saveckpt
Then change devicehive-video-analysis/models/yolo.py's _checkpoint_path = above checkpoint's pwd
python eval_test.py -> devicehive_yolo (TF-Serving loadable exported model)
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=devicehive_yolo --model_base_path=/home/yitao/Documents/fun-project/devicehive-video-analysis/devicehive_yolo_do_need_preprocess >out-001 2>&1
bazel-bin/tensorflow_serving/example/devicehive_yolo_client --server localhost:9000

# For tf-openpose
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=tf_openpose --model_base_path=/home/yitao/Documents/fun-project/tf-pose-estimation/tf_openpose
bazel-bin/tensorflow_serving/example/tf_openpose_client --server localhost:9000

# For olympian_master.proto
python -m grpc.tools.protoc --python_out=. --grpc_python_out=. -I.:./tensorflow tensorflow_serving/apis/olympian_master.proto
mv olympian_master_pb2_grpc.py olympian_master_grpc_pb2.py

# For olympian_worker.proto
python -m grpc.tools.protoc --python_out=. --grpc_python_out=. -I.:./tensorflow tensorflow_serving/apis/olympian_worker.proto
mv olympian_worker_pb2_grpc.py olympian_worker_grpc_pb2.py
!!! remember to modify tensorflow_serving/apis/BUILD accordingly!!!

# For pose_tensorflow
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=pose_tensorflow --model_base_path=/home/yitao/Documents/fun-project/tensorflow-related/pose-tensorflow/pose_tensorflow
bazel-bin/tensorflow_serving/example/pose_tensorflow_client --server localhost:9000

# For Mobilenet
git clone https://github.com/sugartom/tensorflow-for-poets-2.git
cd tensorflow-for-poets-2
python scripts/label_image_tom.py --graph=tf_files/retrained_graph.pb --image=tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_config_file=tfserv.conf.mobilenet >out-001 2>&1
bazel-bin/tensorflow_serving/example/mobilenet_client

# For SSD
git clone https://github.com/sugartom/SSD-Tensorflow
cd SSD-Tensorflow
python tomTest.py
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=exported_ssd --model_base_path=/home/yitao/Documents/fun-project/tensorflow-related/SSD-Tensorflow/exported_ssd
bazel-bin/tensorflow_serving/example/ssd_client
